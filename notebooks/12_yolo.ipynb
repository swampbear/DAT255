{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnKkWPaYR5CQ"
      },
      "source": [
        "# Object detection using YOLO\n",
        "\n",
        "### (Optional notebook - run it if you want to)\n",
        "\n",
        "In this notebook we will have a look at the best-known models for realtime object detecton, called _You Only Look Once_ (YOLO). They now form a family of models that can do different computer vision task, both detection, segmentation, classification, and pose estimation.\n",
        "\n",
        "The best ting is that the models and training framework is fully open source, so we can download and modify the models as we like. Here we will only try out the object detection model, but the documentation is extensive and serves as a nice inspiration for things one can do.\n",
        "\n",
        "We follow the tutorial at https://docs.ultralytics.com/tasks/detect/, and here you can find lots of supplemental information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSHD9ePgTydF"
      },
      "source": [
        "First we need to install the YOLO framework -- which is not built on TensorFLow, but rather on PyTorch.\n",
        "\n",
        "You might want to do this in a separate virtual environment (or on Colab) so that it doesn't mess with your regular python environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yRqnFWWP2Mg"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb8e65oTUPFk"
      },
      "source": [
        "Import the YOLO model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dF11A5uQwMo"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIRkA7_5W4kX"
      },
      "source": [
        "The model comes with optional pre-trained weights, and a simple interface to start training on common datasets, so there is in fact not much we need to do. But let's do a quick training run on a small subset (only 8 images) of the popular [COCO](https://cocodataset.org/#home) (_Common Objects in Context_) dataset, using a pre-trainined model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nmm4L3_yQC4Q"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolo11n.pt\")  # load a pretrained model\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=\"coco8.yaml\",\n",
        "    epochs=1,\n",
        "    imgsz=640\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFjH_KjVYUwz"
      },
      "source": [
        "Test the model on some example images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE-_6JahbMk0"
      },
      "outputs": [],
      "source": [
        "!curl -o forde.jpg https://www.hvl.no/globalassets/hvl-internett/bilde/organisering/volleyball-forde.jpg/Small/\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(filename='forde.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIATMT8CQ5OZ"
      },
      "outputs": [],
      "source": [
        "results = model(['forde.jpg'])\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "\n",
        "    # Various predicted properties:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "\n",
        "    # Display the result overlaid on the test image\n",
        "    result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhATHoLER39A"
      },
      "source": [
        "## Open exercises\n",
        "\n",
        "- Try different images. You can load them directly to the model from an internet link by doing\n",
        "    ```\n",
        "    results = model([\"https://ultralytics.com/images/bus.jpg\"])     # add your own link\n",
        "    ```\n",
        "- Switch to segmentation mode by loading the corresponding model:\n",
        "    ```\n",
        "    model = YOLO(\"yolo11n-seg.pt\")\n",
        "    ```\n",
        "\n",
        "    and try it out on some different images.\n",
        "- Try tracking objects in a video, by following this tutorial: https://docs.ultralytics.com/modes/track/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
