{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaclD1OJ0Kla"
      },
      "source": [
        "# Code classification\n",
        "\n",
        "In this notebook we will classify posts on StackOverflow, by which programming language they pertain to.\n",
        "\n",
        "This dataset is an extract from the public [Stack Overflow dataset](https://console.cloud.google.com/marketplace/details/stack-exchange/stack-overflow), and contains the body of 16,000 posts on four languages (Java, Python, CSharp, and Javascript), which are equally divided into train and test.\n",
        "\n",
        "The keywords \"Java\", \"Python\", \"CSharp\" and \"JavaScript\" have been replaced in each post by the word \"BLANK\" in order to increase the difficulty of this dataset in classification examples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enGhw8720LAz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNwpBTWg0Kjt"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbDZhc-ZRh1A"
      },
      "outputs": [],
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\"\n",
        "\n",
        "dataset_dir = tf.keras.utils.get_file(\n",
        "    'stack_overflow',\n",
        "    origin=url,\n",
        "    extract=True\n",
        ")\n",
        "\n",
        "print('Dataset downloaded to', dataset_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHFQIyaA56sD"
      },
      "source": [
        "Load data as TensorFlow datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcQJYi020yxp"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "seed = 42   # need this for the train-test split\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, 'train'),\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, 'train'),\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    os.path.join(dataset_dir, 'test'),\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9bzIZ6X4cgo"
      },
      "source": [
        "Chack what the classes are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgogSzBn3y-L"
      },
      "outputs": [],
      "source": [
        "for i in range(len(raw_train_ds.class_names)):\n",
        "\n",
        "    print(f\"Label {i} corresponds to {raw_train_ds.class_names[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcSkTL4S4eco"
      },
      "source": [
        "Print the first few entries, aloong with their true class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05Egbpkb2hy9"
      },
      "outputs": [],
      "source": [
        "for batch in raw_train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        text = str(batch[0][i].numpy())\n",
        "        label = batch[1][i].numpy()\n",
        "\n",
        "        print('Text:', text)\n",
        "        print('Class', raw_train_ds.class_names[label])\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwadxrqt4rc8"
      },
      "source": [
        "### <span style=\"color: red;\">Exercise:<span>\n",
        "\n",
        "Now you do the rest!\n",
        "\n",
        "Remember that for these data, removing all non-letters will maybe not be a good idea, since these might give hints to what the programming language the example contains.\n",
        "\n",
        "But, since the data are scaped from the Internet, some characters have been replaced -- for instance, all `<` symbols are stored as `&lt;` and so on.\n",
        "\n",
        "How you deal with this is up to you.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pNYR74p4wwa"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_data):\n",
        "\n",
        "    standardised_data = ???\n",
        "\n",
        "    return standardised_data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
