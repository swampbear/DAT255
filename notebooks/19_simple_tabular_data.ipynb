{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMw-ydqx1_E1"
      },
      "source": [
        "# Model comparison on simple tabular data\n",
        "\n",
        "In this notebook we will try to predict whether or not a patient has diabetes, based on various diagnostic measurements. This is no simple task, but the data we use to train the model contains only numerical data, so preprocessing-wise we can say that the data is relatively simple. In the next notebook we get over to data that requires more work before we get going.\n",
        "\n",
        "Our task is (as ususal) to find the best possible model, so we will carry out a comparison between a deep neural network and tree-based alternatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHi9lCZzJo8T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl4lSI933zKy"
      },
      "source": [
        "### Download the data\n",
        "\n",
        "The data are described at [openml.org](https://www.openml.org/search?type=data&status=active&id=43582&sort=runs). If we download it directly we don't get the usual CSV file, but rather a file including the description and feature names -- so let's do this one-liner that skips all the non-numerical data at the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S9nlRxTEtME"
      },
      "outputs": [],
      "source": [
        "!curl -L https://www.openml.org/data/download/22102407/dataset | awk '/^[0-9]/' > diabetes.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W896gB6SF-pX"
      },
      "outputs": [],
      "source": [
        "! head -n 3 diabetes.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iULLCt_zMU6C"
      },
      "outputs": [],
      "source": [
        "feature_names = [\n",
        "    \"Pregnancies\",\n",
        "    \"Glucose\",\n",
        "    \"BloodPressure\",\n",
        "    \"SkinThickness\",\n",
        "    \"Insulin\",\n",
        "    \"BMI\",\n",
        "    \"DiabetesPedigreeFunction\",\n",
        "    \"Age\",\n",
        "    \"Outcome\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPYnYFM84qeR"
      },
      "source": [
        "## Read the CSV file\n",
        "\n",
        "There are many options for reading and processing CSV files, [pandas](https://pandas.pydata.org/) being the most popular. Numpy is also happy to do it, through the `loadtxt()` function, which can be configured to do various types of preprocessing on the fly. Here we have only numerical data, so no need to configure anything.\n",
        "\n",
        "We should note that simply writing a CSV file reader yourself, using Python's `open()` and `readline()`, is quick and easy and gives you even more fine-grained control of the preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfsQ98KQMQGU"
      },
      "outputs": [],
      "source": [
        "data = np.loadtxt(\n",
        "    'diabetes.csv',\n",
        "    delimiter=',',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVcqLoxl6UhF"
      },
      "source": [
        "Split the data in train, validation and test sets.\n",
        "\n",
        "For a more serious model comparison we should of course consider a crossvalidation study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CucnoKmMMs7v"
      },
      "outputs": [],
      "source": [
        "X = data[:,:-1]\n",
        "y = data[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "print('X_train.shape:', X_train.shape)\n",
        "print('X_val.shape:', X_val.shape)\n",
        "print('X_test.shape:', X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATs0BdmD8GPP"
      },
      "source": [
        "If we like, have a look at the data in form of a pairwise feature scatter plot. This is easiest done with the Pandas and Seaborn libraries, but you can also skip this step or implement the equivalent in Matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTc0oxEp8RKT"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "dataframe = pd.DataFrame(np.column_stack((X_train, y_train)), columns=feature_names)\n",
        "sns.pairplot(dataframe, hue=\"Outcome\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L8Ir1Yd69Fs"
      },
      "source": [
        "Normalise the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzojzdVNNJcH"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler().fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-FAfon1PrDy"
      },
      "source": [
        "## Simple dense network\n",
        "\n",
        "For starters, we construct a simple dense (feed-forward) network, and train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU1ZXM0jPqil"
      },
      "outputs": [],
      "source": [
        "nn_model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train.shape[-1],)),\n",
        "    keras.layers.Dense(32),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttQlMYKhQQ5O"
      },
      "outputs": [],
      "source": [
        "nn_model.compile(\n",
        "    optimizer=\"Adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1szhUKkQgFa"
      },
      "outputs": [],
      "source": [
        "history = nn_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ4diCvH_hDb"
      },
      "source": [
        "Plot the loss and accuracy curves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpBkNfKLRoc6"
      },
      "outputs": [],
      "source": [
        "_, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
        "\n",
        "axs[0].plot(history.history['loss'])\n",
        "axs[0].plot(history.history['val_loss'])\n",
        "axs[0].set_ylabel('Loss')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].legend(['train', 'val'], loc='upper right')\n",
        "axs[1].plot(history.history['accuracy'])\n",
        "axs[1].plot(history.history['val_accuracy'])\n",
        "axs[1].set_ylabel('Accuracy')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].legend(['train', 'val'], loc='upper left')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkm8VXYEAMp6"
      },
      "source": [
        "Let's train some more models before we do the final evaluation on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dUAQGOx1vSG"
      },
      "source": [
        "## Compare to a Random Forest model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRbDh8X81-H1"
      },
      "source": [
        "Now for our first comparison -- a Random Forest model, using the implementation in Scikit-learn.\n",
        "\n",
        "No hyperparameter tuning so far, we just run it with default parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz2y8AKO1uxz"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "val_accuracy = accuracy_score(y_val, rf_model.predict(X_val))\n",
        "print('Validation accuracy:', val_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofVUIFBhTLHj"
      },
      "source": [
        "## Compare to a gradient-boosted decision tree model\n",
        "\n",
        "For a more advanced tree-based model, we turn to gradient boosting. A common high-performance implementation is [XGBoost](https://xgboost.readthedocs.io/en/stable/) (eXtreme Gradient Boosting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw9-3NO1TRN2"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kon4PkYXTePw"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    eval_set=[(X_val, y_val)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0dEeue_BtSN"
      },
      "source": [
        "## Evaluate results on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgwfYfNEVFTQ"
      },
      "outputs": [],
      "source": [
        "preds_nn = nn_model.predict(X_test)\n",
        "accuracy_nn = accuracy_score(y_test, binarize(preds_nn, threshold=0.5))\n",
        "\n",
        "preds_rf = rf_model.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, preds_rf)\n",
        "\n",
        "preds_xgb = xgb_model.predict(X_test)\n",
        "accuracy_xgb = accuracy_score(y_test, preds_xgb)\n",
        "\n",
        "print('Accuracy neural network:', accuracy_nn)\n",
        "print('Accuracy random forest:', accuracy_rf)\n",
        "print('Accuracy XGBoost:', accuracy_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color: red; font-weight: bold;\">Exercise:<span>\n",
        "\n",
        "Build a deep neural network that can beat the other tree-based models. \n",
        "\n",
        "Any network architectures are allowed!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
