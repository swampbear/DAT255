{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gomxMJiQeJOv"
      },
      "source": [
        "# Augmentation\n",
        "\n",
        "In this notebook we take a closer look at _augmentation_, and test its effect by training a convolutional network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAyr1bwjeGZS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5awITigeXz7"
      },
      "source": [
        "## Data loading and preprocessing\n",
        "\n",
        "Again we use the cats and dogs dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvbuY8uof1DS"
      },
      "outputs": [],
      "source": [
        "!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
        "!unzip -q kagglecatsanddogs_5340.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6m-Td28f7rI"
      },
      "source": [
        "Skip corrupted images, like last time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pexbxN6Pf-Wn"
      },
      "outputs": [],
      "source": [
        "num_skipped = 0\n",
        "for folder_name in (\"Cat\", \"Dog\"):\n",
        "    folder_path = os.path.join(\"PetImages\", folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            is_jfif = b\"JFIF\" in fobj.peek(10)\n",
        "        finally:\n",
        "            fobj.close()\n",
        "\n",
        "        if not is_jfif:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "\n",
        "print(f\"Deleted {num_skipped} images.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meOrRnOXgN7i"
      },
      "source": [
        "Load into a TensorFlow dataset, using the Keras utility functions.\n",
        "\n",
        "If the training is going too slow, you can optionally reduce the dimensions of the images (currently set to 180x180 pixels), and adjust the batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6WUb84RgTrf"
      },
      "outputs": [],
      "source": [
        "image_shape = (180, 180, 3) # TODO reduce if needed\n",
        "batch_size = 128\n",
        "\n",
        "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
        "    \"PetImages\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=123,\n",
        "    shuffle=True,\n",
        "    image_size=image_shape[:2],\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es5xUVO4g8mU"
      },
      "source": [
        "Pick some example image and show them.\n",
        "\n",
        "Note that since we set `shuffle=True` in the code cell above, you will see a different image each time you run the cell below. To have the same images each time you can specify `shuffle=False` and have reproducible outputs. For training, however, it's typically better to shuffle the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAsOGlWPhAPg"
      },
      "outputs": [],
      "source": [
        "# Select one single batch from the dataset\n",
        "batch = train_ds.take(1)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "for images, labels in batch:\n",
        "    for i in range(3):\n",
        "        ax = plt.subplot(1, 3, i+1)\n",
        "        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Foff9MnzjpS3"
      },
      "source": [
        "## Adding augmentations\n",
        "\n",
        "In Keras, different types of image augmentations are implemented as layers. This means that once instantiated, they can be used as functions that take in an image and gives a transformed image back. In addition, they can be added as part of a model, just like any other kinds of layers.\n",
        "\n",
        "**Note:** When adding augmentation layers to a model, they should only be active during training, and not during evaluation and inference -- since we don't want to tamper with new images that our finished model is trying to classify. Keras disables the augmentation layers automatically when we run `model.predict()` or `model.evaluate()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g3DLwvMoYgX"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "for images, labels in batch:\n",
        "\n",
        "    images = keras.layers.RandomTranslation(0.2, 0.2)(images)\n",
        "\n",
        "    for i in range(3):\n",
        "        ax = plt.subplot(1, 3, i+1)\n",
        "        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIlG9JMIpgkt"
      },
      "source": [
        "### <span style=\"color: red; font-weight: bold;\">Exercise:<span>\n",
        "\n",
        "Make the same plots as above, but for all the available augmentation techniques in https://keras.io/api/layers/preprocessing_layers/image_augmentation/.\n",
        "\n",
        "Put them in a nice layout so that you can compare the effects for each type.\n",
        "\n",
        "_Hint:_ In case you find it useful to add the augmentation layers in a list and iterate through it, the first element can be a `keras.layers.Identity()` layer, which does nothing except return the original image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tXD3Xqzu6uh"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gfbKCdQu8w3"
      },
      "source": [
        "## Train some models\n",
        "\n",
        "Now it is time to put our augmentations to the test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB3h4I6Uv1O-"
      },
      "source": [
        "### Baseline model\n",
        "\n",
        "For a comparison, let's first train a model with **no** augmentation, on the **full** training dataset (18 728) images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wkh7kf4zv0Wo"
      },
      "outputs": [],
      "source": [
        "baseline_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=image_shape),\n",
        "        keras.layers.Rescaling(1.0/255),    # Standardise the images\n",
        "        keras.layers.Conv2D(64, 3, kernel_initializer='he_uniform', padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Activation('relu'),\n",
        "        keras.layers.MaxPooling2D(3, padding='same'),\n",
        "        keras.layers.Conv2D(64, 3, kernel_initializer='he_uniform', padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Activation('relu'),\n",
        "        keras.layers.MaxPooling2D(3, padding='same'),\n",
        "        keras.layers.Conv2D(64, 3, kernel_initializer='he_uniform', padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Activation('relu'),\n",
        "        keras.layers.GlobalAveragePooling2D(),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "baseline_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QXTer7yQwiB3"
      },
      "outputs": [],
      "source": [
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=3, min_lr=0.0001, verbose=1)\n",
        "early_stop = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "baseline_model.fit(\n",
        "    train_ds,\n",
        "    epochs=20,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ1aDp5TzryR"
      },
      "source": [
        "The final evaluation of the baseline model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekE-GPzS081G"
      },
      "outputs": [],
      "source": [
        "baseline_result = baseline_model.evaluate(val_ds, verbose=0)\n",
        "print()\n",
        "print('Accuracy of the baseline model was {}%'.format(baseline_result[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-oyrc7X2eEB"
      },
      "source": [
        "## Train on augmented data\n",
        "\n",
        "Now for the challenge: We **remove** images from the training set, and our task is to match (or maybe even exceed?) the performance of the baseline model.\n",
        "\n",
        "Let's make the training dataset 2/3 the size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywiZUDnr22Pe"
      },
      "outputs": [],
      "source": [
        "reduced_train_ds = train_ds.take((2*len(train_ds))//3)\n",
        "print('train_ds contains', len(train_ds), 'batches (of 128 images each)')\n",
        "print('reduced_train_ds contains', len(reduced_train_ds), 'batches')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXClTHO529xF"
      },
      "source": [
        "### <span style=\"color: red; font-weight: bold;\">Exercise:<span>\n",
        "\n",
        "Now, add your favourite augmentation layers to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLeLXCDE3FzF"
      },
      "outputs": [],
      "source": [
        "augmented_model = keras.Sequential(\n",
        "    [\n",
        "        # TODO\n",
        "        # Add augmentation\n",
        "        keras.Input(shape=image_shape),\n",
        "        keras.layers.Rescaling(1.0/255),\n",
        "        keras.layers.Conv2D(64, 3, kernel_initializer='he_uniform', padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Activation('relu'),\n",
        "        keras.layers.MaxPooling2D(3, padding='same'),\n",
        "        keras.layers.Conv2D(64, 3, kernel_initializer='he_uniform', padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Activation('relu'),\n",
        "        keras.layers.MaxPooling2D(3, padding='same'),\n",
        "        keras.layers.Conv2D(64, 3, kernel_initializer='he_uniform', padding='same'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Activation('relu'),\n",
        "        keras.layers.GlobalAveragePooling2D(),\n",
        "        keras.layers.Dropout(0.4),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "augmented_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=3, min_lr=0.0001, verbose=1)\n",
        "early_stop = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "augmented_model.fit(\n",
        "    reduced_train_ds,   # use the correct dataset\n",
        "    epochs=20,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh1vOYbj-kyl"
      },
      "outputs": [],
      "source": [
        "augmented_result = augmented_model.evaluate(val_ds, verbose=0)\n",
        "print('Accuracy of the augmented model was {}%'.format(augmented_result[1]*100))\n",
        "\n",
        "if augmented_result[1] > baseline_result[1]:\n",
        "    print()\n",
        "    print('You\\'re awesome!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYzUVrhCAfIL"
      },
      "source": [
        "For the finale, train the augmented model on the full dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPUBoM_m0lMm"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39_jfHsIAryM"
      },
      "outputs": [],
      "source": [
        "full_result = augmented_model_full_dataset.evaluate(val_ds)\n",
        "print('Accuracy of the augmented model in full dataset was {}%'.format(full_result[1]*100))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
