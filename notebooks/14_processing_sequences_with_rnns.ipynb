{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR9hxR1FR99p"
      },
      "source": [
        "# Processing sequences using RNNs and CNNs\n",
        "\n",
        "This notebook reproduces the results we see in Chapter 15 in the textbook. For more execises from the book, see the authors' GitHub repository: https://github.com/ageron/handson-ml3/ Here you will find the solutions to the exercises below,\n",
        "so don't look before you tried solving them yourself :)\n",
        "\n",
        "Some comments and changes have been added to Geron's original notebook, just for clarity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFXIv9qNpKzt",
        "tags": []
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Piq5se2pKzx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDaDoLQTpKzx"
      },
      "source": [
        "Matplotlib settings to adjust the figures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d4TH3NbpKzx"
      },
      "outputs": [],
      "source": [
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcoUIRsvpKzy"
      },
      "source": [
        "A function to save images to `images/rnn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQFH5Y9PpKzy"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"rnn\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrUZ4IzjR99y"
      },
      "source": [
        "## Basic RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-wnFWcER99y"
      },
      "source": [
        "Let's download the ridership data from the ageron/data project. It originally comes from Chicago's Transit Authority, and was downloaded from the [Chicago's Data Portal](https://homl.info/ridership)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIyD7rpqR99y",
        "outputId": "c5903a33-0e16-4c11-d901-8b254840cb63"
      },
      "outputs": [],
      "source": [
        "filepath = tf.keras.utils.get_file(\n",
        "    \"ridership.tgz\",\n",
        "    \"https://github.com/ageron/data/raw/main/ridership.tgz\",\n",
        "    cache_dir=\".\",\n",
        "    extract=True\n",
        ")\n",
        "if \"_extracted\" in filepath:\n",
        "    ridership_path = Path(filepath) / \"ridership\"\n",
        "else:\n",
        "    ridership_path = Path(filepath).with_name(\"ridership\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xECl8hDhfNDa"
      },
      "source": [
        "Check that the file exists:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYaYKWWNSK_a",
        "outputId": "d6c46727-d726-403a-85b9-926f64fb96f7"
      },
      "outputs": [],
      "source": [
        "!ls datasets/ridership_extracted/ridership/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFrp0kwXfU-l"
      },
      "source": [
        "For convenience we use the Pandas library to read the CSV file and do some minor data manipulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQN-jA61R99z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path(\"datasets/ridership_extracted/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv\")\n",
        "df = pd.read_csv(path, parse_dates=[\"service_date\"])\n",
        "df.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"]  # shorter names\n",
        "df = df.sort_values(\"date\").set_index(\"date\")\n",
        "df = df.drop(\"total\", axis=1)  # no need for total, it's just bus + rail\n",
        "df = df.drop_duplicates()  # remove duplicated months (2011-10 and 2014-07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "vXIwJrF0R99z",
        "outputId": "b992f57e-801f-40d2-9358-b4f7b497a17e"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp8p_wnuR990"
      },
      "source": [
        "Let's look at the first few months of 2019 (note that Pandas treats the range boundaries as inclusive):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "S6p0Cp9OR990",
        "outputId": "8d2d428c-456c-47a8-cb8c-899d8a05b330"
      },
      "outputs": [],
      "source": [
        "df[\"2019-03\":\"2019-04\"].plot(grid=True, marker=\".\", figsize=(8, 5))\n",
        "save_fig(\"daily_ridership_plot\")  # extra code – saves the figure for the book\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMo3f8YRfzOV"
      },
      "source": [
        "Now, let's look at the difference between each time step and the same dat last week. We can compute this by using the [`diff`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html) function.\n",
        "\n",
        "Does it look like there is always the same number of travellers each Tuesday?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "b1T9FunBR990",
        "outputId": "6ec3eaa4-f90f-478e-e1f2-f474d2566cef"
      },
      "outputs": [],
      "source": [
        "diff_7 = df[[\"bus\", \"rail\"]].diff(7)[\"2019-03\":\"2019-05\"]\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(8, 5))\n",
        "df.plot(ax=axs[0], legend=False, marker=\".\")  # original time series\n",
        "df.shift(7).plot(ax=axs[0], grid=True, legend=False, linestyle=\":\")  # lagged\n",
        "diff_7.plot(ax=axs[1], grid=True, marker=\".\")  # 7-day difference time series\n",
        "axs[0].set_ylim([170_000, 900_000])  # extra code – beautifies the plot\n",
        "save_fig(\"differencing_plot\")  # extra code – saves the figure for the book\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igqpzvxpR991",
        "outputId": "8570aa54-30bb-4b4f-e739-b87d31cd0b69",
        "tags": []
      },
      "outputs": [],
      "source": [
        "list(df.loc[\"2019-05-25\":\"2019-05-27\"][\"day_type\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx8_RZMdR991"
      },
      "source": [
        "## Simple prediction\n",
        "Is the number of travellers on the same day last week, a good estimate of the number of travellers today? Compute the mean absolute error (MAE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "EWOIbZhTR991",
        "outputId": "0943c49f-e57d-45d3-e8ed-e10494778d75"
      },
      "outputs": [],
      "source": [
        "diff_7.abs().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDixzStcR991"
      },
      "source": [
        "Mean absolute percentage error (MAPE):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "UQ2u7GcqR991",
        "outputId": "e886ea5a-7d4c-49f1-f80b-97bd0fe1b3e6"
      },
      "outputs": [],
      "source": [
        "targets = df[[\"bus\", \"rail\"]][\"2019-03\":\"2019-05\"]\n",
        "(diff_7 / targets).abs().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3ZcfdnHR992"
      },
      "source": [
        "Now let's look at the yearly seasonality and the long-term trends:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHbRCPTyR992"
      },
      "source": [
        "(**Warning**: Pandas' API to compute the mean for each month has changed quite a bit, so the code below tries the newest API, and falls back to an older API, and if that also fails, it falls back to the code in the book.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "2dN6bfSiR992",
        "outputId": "b02816d6-e2c3-4703-adfe-fe06a2314858"
      },
      "outputs": [],
      "source": [
        "period = slice(\"2001\", \"2019\")\n",
        "try:\n",
        "    df_monthly = df.select_dtypes(include=\"number\").resample('ME').mean()  # compute the mean for each month\n",
        "    rolling_average_12_months = df_monthly.loc[period].rolling(window=12).mean()\n",
        "except ValueError as ex:\n",
        "    try:\n",
        "        df_monthly = df.select_dtypes(include=\"number\").resample('M').mean()  # compute the mean for each month\n",
        "        rolling_average_12_months = df_monthly.loc[period].rolling(window=12).mean()\n",
        "    except ValueError as ex:\n",
        "        df_monthly = df.resample('M').mean()  # compute the mean for each month\n",
        "        rolling_average_12_months = df_monthly[period].rolling(window=12).mean()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "df_monthly[period].plot(ax=ax, marker=\".\")\n",
        "rolling_average_12_months.plot(ax=ax, grid=True, legend=False)\n",
        "save_fig(\"long_term_ridership_plot\")  # extra code – saves the figure for the book\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lFnRCEtHR992",
        "outputId": "20106735-1ffc-4055-c558-8969c7b6be22"
      },
      "outputs": [],
      "source": [
        "df_monthly.diff(12)[period].plot(grid=True, marker=\".\", figsize=(8, 3))\n",
        "save_fig(\"yearly_diff_plot\")  # extra code – saves the figure for the book\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l3M8O5Hg9Pr"
      },
      "source": [
        "## Optional: Build an ARIMA model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-9BH4L8R992"
      },
      "source": [
        "Install the statsmodels library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOV0oqCsR992"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f3Pbc1TR994"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "origin, today = \"2019-01-01\", \"2019-05-31\"\n",
        "rail_series = df.loc[origin:today][\"rail\"].asfreq(\"D\")\n",
        "model = ARIMA(rail_series,\n",
        "              order=(1, 0, 0),\n",
        "              seasonal_order=(0, 1, 1, 7))\n",
        "model = model.fit()\n",
        "y_pred = model.forecast()  # returns 427,758.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHQ2sa-SR994",
        "outputId": "8e559c5d-15fa-457c-b40c-45a3639ca869"
      },
      "outputs": [],
      "source": [
        "y_pred[0]  # ARIMA forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd2DU2IZR994",
        "outputId": "9cc39783-0bd0-43bc-9df9-f6490cc3c5c9"
      },
      "outputs": [],
      "source": [
        "df[\"rail\"].loc[\"2019-06-01\"]  # target value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eC78L4NR994",
        "outputId": "59d858e0-9297-4a93-ac4d-71b4288feb58"
      },
      "outputs": [],
      "source": [
        "df[\"rail\"].loc[\"2019-05-25\"]  # naive forecast (value from one week earlier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bvCGITchS_m"
      },
      "source": [
        "Compute the mean average error for the ARIMA model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_9d74uLR994"
      },
      "outputs": [],
      "source": [
        "origin, start_date, end_date = \"2019-01-01\", \"2019-03-01\", \"2019-05-31\"\n",
        "time_period = pd.date_range(start_date, end_date)\n",
        "rail_series = df.loc[origin:end_date][\"rail\"].asfreq(\"D\")\n",
        "y_preds = []\n",
        "for today in time_period.shift(-1):\n",
        "    model = ARIMA(rail_series[origin:today],  # train on data up to \"today\"\n",
        "                  order=(1, 0, 0),\n",
        "                  seasonal_order=(0, 1, 1, 7))\n",
        "    model = model.fit()  # note that we retrain the model every day!\n",
        "    y_pred = model.forecast().iloc[0]\n",
        "    y_preds.append(y_pred)\n",
        "\n",
        "y_preds = pd.Series(y_preds, index=time_period)\n",
        "mae = (y_preds - rail_series[time_period]).abs().mean()  # returns 32,040.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9tNLWh-R995",
        "outputId": "420e0580-9cfe-480f-b74a-f751da87c46c"
      },
      "outputs": [],
      "source": [
        "mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "gATqESBwR995",
        "outputId": "2252698d-50ac-476d-9384-eab7d3284f82"
      },
      "outputs": [],
      "source": [
        "# extra code – displays the SARIMA forecasts\n",
        "fig, ax = plt.subplots(figsize=(8, 3))\n",
        "rail_series.loc[time_period].plot(label=\"True\", ax=ax, marker=\".\", grid=True)\n",
        "ax.plot(y_preds, color=\"r\", marker=\".\", label=\"ARIMA Forecasts\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "v9jfoiFjR995",
        "outputId": "43324e57-2e89-47d8-a17e-caeb751acbab"
      },
      "outputs": [],
      "source": [
        "# extra code – shows how to plot the Autocorrelation Function (ACF) and the\n",
        "#              Partial Autocorrelation Function (PACF)\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18, 7))\n",
        "plot_acf(df[period][\"rail\"], ax=axs[0], lags=35)\n",
        "axs[0].grid()\n",
        "plot_pacf(df[period][\"rail\"], ax=axs[1], lags=35, method=\"ywm\")\n",
        "axs[1].grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fKxJf7yhc7L"
      },
      "source": [
        "## Using `tf.data.Dataset` with time series\n",
        "\n",
        "Once we have the data loaded as a NumPy array, we can convert it into a batched TensorFlow dataset using the `timeseries_dataset_from_array` utility function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pt9PMBkR995",
        "outputId": "d4c7269c-a417-40d7-c4bb-9af4e88f1e19"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "my_series = [0, 1, 2, 3, 4, 5]\n",
        "my_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    my_series,\n",
        "    targets=my_series[3:],  # the targets are 3 steps into the future\n",
        "    sequence_length=3,\n",
        "    batch_size=2\n",
        ")\n",
        "list(my_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAoE-BkTR996",
        "outputId": "dba796ec-0c93-4a34-b555-20075f4723d6"
      },
      "outputs": [],
      "source": [
        "for window_dataset in tf.data.Dataset.range(6).window(4, shift=1):\n",
        "    for element in window_dataset:\n",
        "        print(f\"{element}\", end=\" \")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtNvJ_X_R996",
        "outputId": "28e23569-4c5f-431e-97e2-328b90c5c01e"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.range(6).window(4, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window_dataset: window_dataset.batch(4))\n",
        "for window_tensor in dataset:\n",
        "    print(f\"{window_tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJvkG_2MR996"
      },
      "outputs": [],
      "source": [
        "def to_windows(dataset, length):\n",
        "    dataset = dataset.window(length, shift=1, drop_remainder=True)\n",
        "    return dataset.flat_map(lambda window_ds: window_ds.batch(length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2YHWdteR996",
        "outputId": "70b6e68d-bce4-4a60-c2a4-4ede0d38fe25"
      },
      "outputs": [],
      "source": [
        "dataset = to_windows(tf.data.Dataset.range(6), 4)\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "list(dataset.batch(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-2aVHLkR997"
      },
      "source": [
        "Before we continue looking at the data, let's split the time series into three periods, for training, validation and testing. We won't look at the test data for now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9DJOoecR997"
      },
      "outputs": [],
      "source": [
        "rail_train = df[\"rail\"][\"2016-01\":\"2018-12\"] / 1e6\n",
        "rail_valid = df[\"rail\"][\"2019-01\":\"2019-05\"] / 1e6\n",
        "rail_test = df[\"rail\"][\"2019-06\":] / 1e6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrx0f0toR997"
      },
      "outputs": [],
      "source": [
        "seq_length = 56\n",
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    rail_train.to_numpy(),\n",
        "    targets=rail_train[seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    rail_valid.to_numpy(),\n",
        "    targets=rail_valid[seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6rNLEOth_NW"
      },
      "source": [
        "## Train a simple dense network\n",
        "\n",
        "For our first network, we try a dead simple approach with a single `Dense` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGd_Fj1fR997",
        "outputId": "6f4074fb-b35a-47d3-bc74-2ff52bb83b7b"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[seq_length])\n",
        "])\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
        "history = model.fit(train_ds, validation_data=valid_ds, epochs=500,\n",
        "                    callbacks=[early_stopping_cb])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wBSSkNUiOWu"
      },
      "source": [
        "Evaluate the prediction preformance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWrhFYQaR998",
        "outputId": "1e7525c4-2e12-4568-d6aa-80a2457ef55e"
      },
      "outputs": [],
      "source": [
        "valid_loss, valid_mae = model.evaluate(valid_ds, verbose=0)\n",
        "print('Validation MAE:', valid_mae * 1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee0W3BwcR998"
      },
      "source": [
        "## Train a simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-b-6OCaR998",
        "outputId": "7d8b29a4-eb6f-497a-957a-a2334710be71"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6wjHPU4R998"
      },
      "outputs": [],
      "source": [
        "# extra code – defines a utility function we'll reuse several times\n",
        "\n",
        "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=500):\n",
        "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_mae\",\n",
        "        patience=50,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.Huber(),\n",
        "        optimizer=opt,\n",
        "        metrics=[\"mae\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_set,\n",
        "        validation_data=valid_set,\n",
        "        epochs=epochs,\n",
        "        callbacks=[early_stopping_cb]\n",
        "    )\n",
        "    valid_loss, valid_mae = model.evaluate(valid_set)\n",
        "    return valid_mae * 1e6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "6TuTJYQIR999",
        "outputId": "8710eacd-7164-4608-ab91-b52517457b80"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(model, train_ds, valid_ds, learning_rate=0.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fI0bDoZi0_1"
      },
      "source": [
        "Define the simple RNN network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhnJgsTAR999"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "univar_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
        "    tf.keras.layers.Dense(1)  # no activation function by default\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVPDqQh3R999"
      },
      "outputs": [],
      "source": [
        "# extra code – compiles, fits, and evaluates the model, like earlier\n",
        "fit_and_evaluate(univar_model, train_ds, valid_ds, learning_rate=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCvee4YvR999"
      },
      "source": [
        "## Train a deep RNN\n",
        "\n",
        "### <span style=\"color: red; font-weight: bold;\">Exercise:<span>\n",
        "\n",
        "This model won't run, because we have forgotten some arguments to the stacked `SimpleRNN` layers. Fix them, and run the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "YQcxWhAvR999",
        "outputId": "5c73c02d-8272-48b7-ba9a-c96ccb817aec"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "deep_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
        "    tf.keras.layers.SimpleRNN(32),\n",
        "    tf.keras.layers.SimpleRNN(32),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "g_w9UCaNR999",
        "outputId": "77069e33-bcad-4152-ebac-a381ef811a94"
      },
      "outputs": [],
      "source": [
        "# extra code – compiles, fits, and evaluates the model, like earlier\n",
        "fit_and_evaluate(deep_model, train_ds, valid_ds, learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e52Aq84DR999"
      },
      "source": [
        "## Multivariate time series\n",
        "\n",
        "Since we have additional observables in the dataset, we can add those to out model too, and se if the results improve:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8unpUDcZR999"
      },
      "outputs": [],
      "source": [
        "df_mulvar = df[[\"bus\", \"rail\"]] / 1e6  # use both bus & rail series as input\n",
        "df_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1)  # we know tomorrow's type\n",
        "df_mulvar = pd.get_dummies(df_mulvar, dtype=float)  # one-hot encode the day type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGOuZ4wXR99-"
      },
      "outputs": [],
      "source": [
        "mulvar_train = df_mulvar[\"2016-01\":\"2018-12\"]\n",
        "mulvar_valid = df_mulvar[\"2019-01\":\"2019-05\"]\n",
        "mulvar_test = df_mulvar[\"2019-06\":]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqG9JetPR99-"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "\n",
        "train_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_train.to_numpy(),  # use all 5 columns as input\n",
        "    targets=mulvar_train[\"rail\"][seq_length:],  # forecast only the rail series\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "valid_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_valid.to_numpy(),\n",
        "    targets=mulvar_valid[\"rail\"][seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUd_TR2nkgv7"
      },
      "source": [
        "### <span style=\"color: red; font-weight: bold;\">Exercise:<span>\n",
        "\n",
        "Implement a single-layer RNNs as before, which now has the correct input shape to match the new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG_GXiy_R99-"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "mulvar_model = tf.keras.Sequential([\n",
        "    ...\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CQ8dOA4R99-",
        "outputId": "2233e581-6c6f-4170-e23e-76ec0915c3ff"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(mulvar_model, train_mulvar_ds, valid_mulvar_ds,\n",
        "                 learning_rate=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Opcaxvk1B_"
      },
      "source": [
        "### Adding targets to our dataset\n",
        "\n",
        "Now we try and predict both the number of rail passengers and bus passengers at the same time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yQ7F1i8R99-",
        "outputId": "b61b7db4-1197-4311-cea2-a6549edcfebf"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "seq_length = 56\n",
        "train_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_train.to_numpy(),\n",
        "    targets=mulvar_train[[\"bus\", \"rail\"]][seq_length:],  # 2 targets per day\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "valid_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_valid.to_numpy(),\n",
        "    targets=mulvar_valid[[\"bus\", \"rail\"]][seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he5pbVPilGNl"
      },
      "source": [
        "### <span style=\"color: red; font-weight: bold;\">Exercise:<span>\n",
        "\n",
        "Again make a simple RNN network, which now can predict two outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKl1u_dflOqD"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "multask_model = tf.keras.Sequential([\n",
        "    ...\n",
        "])\n",
        "\n",
        "fit_and_evaluate(multask_model, train_multask_ds, valid_multask_ds,\n",
        "                 learning_rate=0.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeG9X8zHR9-A"
      },
      "source": [
        "## Forecasting Several Steps Ahead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH656vjuR9-A",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = rail_valid.to_numpy()[np.newaxis, :seq_length, np.newaxis]\n",
        "for step_ahead in range(14):\n",
        "    y_pred_one = univar_model.predict(X)\n",
        "    X = np.concatenate([X, y_pred_one.reshape(1, 1, 1)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i1QHmayR9-A",
        "outputId": "e48aa681-e84d-407b-a83d-74220113b1b8"
      },
      "outputs": [],
      "source": [
        "# extra code – generates and saves Figure 15–11\n",
        "\n",
        "# The forecasts start on 2019-02-26, as it is the 57th day of 2019, and they end\n",
        "# on 2019-03-11. That's 14 days in total.\n",
        "Y_pred = pd.Series(X[0, -14:, 0],\n",
        "                   index=pd.date_range(\"2019-02-26\", \"2019-03-11\"))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 3.5))\n",
        "(rail_valid * 1e6)[\"2019-02-01\":\"2019-03-11\"].plot(\n",
        "    label=\"True\", marker=\".\", ax=ax)\n",
        "(Y_pred * 1e6).plot(\n",
        "    label=\"Predictions\", grid=True, marker=\"x\", color=\"r\", ax=ax)\n",
        "ax.vlines(\"2019-02-25\", 0, 1e6, color=\"k\", linestyle=\"--\", label=\"Today\")\n",
        "ax.set_ylim([200_000, 800_000])\n",
        "plt.legend(loc=\"center left\")\n",
        "save_fig(\"forecast_ahead_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThHH4j4PR9-B"
      },
      "source": [
        "Now let's create an RNN that predicts all 14 next values at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7pk75AOR9-B"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "\n",
        "def split_inputs_and_targets(mulvar_series, ahead=14, target_col=1):\n",
        "    return mulvar_series[:, :-ahead], mulvar_series[:, -ahead:, target_col]\n",
        "\n",
        "ahead_train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_train.to_numpy(),\n",
        "    targets=None,\n",
        "    sequence_length=seq_length + 14,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ").map(split_inputs_and_targets)\n",
        "ahead_valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_valid.to_numpy(),\n",
        "    targets=None,\n",
        "    sequence_length=seq_length + 14,\n",
        "    batch_size=32\n",
        ").map(split_inputs_and_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62IsJxxhR9-B"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "ahead_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1hza1HcR9-B",
        "outputId": "7687fad8-5643-4217-8031-5a85d385b59b"
      },
      "outputs": [],
      "source": [
        "# extra code – compiles, fits, and evaluates the model, like earlier\n",
        "fit_and_evaluate(ahead_model, ahead_train_ds, ahead_valid_ds,\n",
        "                 learning_rate=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxT82eX4R9-B"
      },
      "outputs": [],
      "source": [
        "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]  # shape [1, 56, 5]\n",
        "Y_pred = ahead_model.predict(X)  # shape [1, 14]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9bA04gJR9-B"
      },
      "source": [
        "Now let's create an RNN that predicts the next 14 steps at each time step. That is, instead of just forecasting time steps 56 to 69 based on time steps 0 to 55, it will forecast time steps 1 to 14 at time step 0, then time steps 2 to 15 at time step 1, and so on, and finally it will forecast time steps 56 to 69 at the last time step. Notice that the model is causal: when it makes predictions at any time step, it can only see past time steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTGCByT5R9-B"
      },
      "source": [
        "To prepare the datasets, we can use `to_windows()` twice, to get sequences of consecutive windows, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uyFTK9RR9-B",
        "outputId": "be1a32b2-cb69-4415-8ec6-602884aea939"
      },
      "outputs": [],
      "source": [
        "my_series = tf.data.Dataset.range(7)\n",
        "dataset = to_windows(to_windows(my_series, 3), 4)\n",
        "list(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx1A8ZuMR9-C"
      },
      "source": [
        "Then we can split these elements into the desired inputs and targets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9wO9VnUR9-C",
        "outputId": "6c583eba-0113-4428-81df-8694b9187ec6"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(lambda S: (S[:, 0], S[:, 1:]))\n",
        "list(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJEXEw5rR9-C"
      },
      "source": [
        "Let's wrap this idea into a utility function. It will also take care of shuffling (optional) and batching:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92kwTztgR9-C"
      },
      "outputs": [],
      "source": [
        "def to_seq2seq_dataset(series, seq_length=56, ahead=14, target_col=1,\n",
        "                       batch_size=32, shuffle=False, seed=None):\n",
        "    ds = to_windows(tf.data.Dataset.from_tensor_slices(series), ahead + 1)\n",
        "    ds = to_windows(ds, seq_length).map(\n",
        "        lambda S: (S[:, 0], S[:, 1:, target_col]))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
        "    return ds.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s57iluwR9-C"
      },
      "outputs": [],
      "source": [
        "seq2seq_train = to_seq2seq_dataset(mulvar_train, shuffle=True, seed=42)\n",
        "seq2seq_valid = to_seq2seq_dataset(mulvar_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_CcCSV9R9-C"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "seq2seq_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "    # equivalent: tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(14))\n",
        "    # also equivalent: tf.keras.layers.Conv1D(14, kernel_size=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87fMiYmIR9-C",
        "outputId": "2ab96747-508a-446f-9982-945b199acb9b"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(seq2seq_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0t90MnBR9-D"
      },
      "outputs": [],
      "source": [
        "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]\n",
        "y_pred_14 = seq2seq_model.predict(X)[0, -1]  # only the last time step's output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4F97ILNR9-D",
        "outputId": "bf6d7cdb-4272-446e-cac6-bd4e6fe0215a"
      },
      "outputs": [],
      "source": [
        "Y_pred_valid = seq2seq_model.predict(seq2seq_valid)\n",
        "for ahead in range(14):\n",
        "    preds = pd.Series(Y_pred_valid[:-1, -1, ahead],\n",
        "                      index=mulvar_valid.index[56 + ahead : -14 + ahead])\n",
        "    mae = (preds - mulvar_valid[\"rail\"]).abs().mean() * 1e6\n",
        "    print(f\"MAE for +{ahead + 1}: {mae:,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bH-30n1R9-D"
      },
      "source": [
        "## Adding layer normalisation\n",
        "\n",
        "To add layer normalisation (`keras.layers.LayerNormalization`), we should put it in between the RNN layer and the activation function.\n",
        "\n",
        "The book does this in a somewhat fancy way, by subclassing the generic Keras `Layer` and making a custom one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUgBL94HR9-D"
      },
      "outputs": [],
      "source": [
        "class LNSimpleRNNCell(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.state_size = units\n",
        "        self.output_size = units\n",
        "        self.simple_rnn_cell = tf.keras.layers.SimpleRNNCell(units,activation=None)\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
        "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
        "        return norm_outputs, [norm_outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R12ThzCfR9-D"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "custom_ln_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.RNN(LNSimpleRNNCell(32), return_sequences=True,\n",
        "                        input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0h95fv0R9-E"
      },
      "source": [
        "Just training for 5 epochs to show that it works (you can increase this if you want):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fim66urR9-E",
        "outputId": "01cd14fe-07f6-4dda-fc66-c3043b14a2e2"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(custom_ln_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV1AucTtR9-G"
      },
      "source": [
        "## Train an LSTM network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9wXUJsZR9-G",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXAtig5zR9-G"
      },
      "source": [
        "Just training for 5 epochs to show that it works (you can increase this if you want):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBuB7aoGR9-G",
        "outputId": "fecb6297-6018-4d3d-96d5-b869008a36c5"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(lstm_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxLVq07nR9-G"
      },
      "source": [
        "## Train a GRU network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dxnmOWrR9-G",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "gru_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsIiJ-pWR9-H"
      },
      "source": [
        "Just training for 5 epochs to show that it works (you can increase this if you want):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjIrCsslR9-H",
        "outputId": "ea985016-532a-45ba-e06c-87b00fc01658"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(gru_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0vMqwbnR9-H"
      },
      "source": [
        "## Using One-Dimensional Convolutional Layers to Process Sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbY7_TVYR9-H"
      },
      "source": [
        "```\n",
        "  |-----0-----|      |-----3----|      |--... |-------52------|\n",
        "         |-----1----|      |-----4----|   ... |       |-------53------|\n",
        "               |-----2----|     |------5--...-51------|       |-------54------|\n",
        "X:  0  1  2  3  4  5  6  7  8  9 10 11 12 ...  104 105 106 107 108 109 110 111\n",
        "Y:      from 4     6     8    10    12    ...      106     108     110     112\n",
        "         to 17    19    21    23    25    ...      119     121     123     125\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDn-xaf3R9-H"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
        "conv_rnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=2,\n",
        "                           activation=\"relu\", input_shape=[None, 5]),\n",
        "    tf.keras.layers.GRU(32, return_sequences=True),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])\n",
        "\n",
        "longer_train = to_seq2seq_dataset(mulvar_train, seq_length=112,\n",
        "                                       shuffle=True, seed=42)\n",
        "longer_valid = to_seq2seq_dataset(mulvar_valid, seq_length=112)\n",
        "downsampled_train = longer_train.map(lambda X, Y: (X, Y[:, 3::2]))\n",
        "downsampled_valid = longer_valid.map(lambda X, Y: (X, Y[:, 3::2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiMKG1MBR9-H"
      },
      "source": [
        "Just training for 5 epochs to show that it works (you can increase this if you want):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42rnXAuPR9-I",
        "outputId": "11f49a24-25f6-4ad5-85a4-384526106de6"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(conv_rnn_model, downsampled_train, downsampled_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
